{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "europeana-fulltext-processing-example1",
      "provenance": [],
      "collapsed_sections": [
        "R37WTGe-Y-fx",
        "nD6JXHZBY0BA"
      ],
      "authorship_tag": "ABX9TyMmb+eo1OmWyMwoHLGp2DfY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dbb4214712ba498ca613df201a9ee1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc0fa470bd2c46d1a9d416396fa150e7",
            "_dom_classes": [],
            "description": "Retrieving:",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 3362,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3362,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6a9d7ace1434bb6844aa089a6acd3e2"
          }
        },
        "bc0fa470bd2c46d1a9d416396fa150e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6a9d7ace1434bb6844aa089a6acd3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twagoo/europeana_colab/blob/master/europeana_fulltext_processing_example1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preamble: imports, logic and configuration"
      ],
      "metadata": {
        "id": "R37WTGe-Y-fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports and utility functions\n",
        "import ipywidgets as widgets\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "import shelve\n",
        "\n",
        "from lxml import etree\n",
        "from IPython.display import display\n",
        "\n",
        "TEXT_RESOURCE_PROFILE_ID = 'clarin.eu:cr1:p_1633000337997'\n",
        "CMD_NAMESPACES = {\n",
        "    'cmd': 'http://www.clarin.eu/cmd/1',\n",
        "    'cmdp': 'http://www.clarin.eu/cmd/1/profiles/clarin.eu:cr1:p_1633000337997'\n",
        "}\n",
        "FULLTEXT_RESOURCES_BASE_URL='https://www.europeana.eu/api/fulltext'\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "def flatten_list(t):\n",
        "  return [item for sublist in t for item in sublist]\n",
        "\n",
        "\n",
        "def retrieve_cmdis_archive(url, filename='cmdis.tgz'):\n",
        "  cmdis_zip = requests.get(url, allow_redirects=True)\n",
        "  with open(filename, 'wb') as tarball:\n",
        "    tarball.write(cmdis_zip.content)\n",
        "  return filename\n",
        "\n",
        "\n",
        "def unpack_collection(tarball_filename, target_dir, collection):\n",
        "  try:\n",
        "    with tarfile.open(tarball_filename, 'r:gz') as tarball:\n",
        "      if collection in tarball.getnames():\n",
        "        members = [tar_info for tar_info in tarball.getmembers()\n",
        "                  if tar_info.name.startswith(f'{collection}/')]\n",
        "        if len(members) > 0:\n",
        "          logger.info(f'Extracting {collection} from {tarball_filename} to {target_dir}/')\n",
        "          tarball.extractall(members=members, path=target_dir)\n",
        "          return True\n",
        "      else:\n",
        "        logger.warning(f'{collection} not found in tarball')\n",
        "  except Exception as ex:\n",
        "    logger.error(f'Something went wrong while trying to extract CMDIs from tarball: {ex}')\n",
        "  return False\n",
        "\n",
        "\n",
        "def index_filenames(index_def, cmdi_files_dir):\n",
        "  index = {}\n",
        "  for filename in os.listdir(cmdi_files_dir):\n",
        "    if not (filename.endswith(\".xml\") or filename.endswith(\".cmdi\")):\n",
        "      logger.info(f\"Skipping file {filename} (not an XML file)\")\n",
        "    else:\n",
        "      file_path = f'{cmdi_files_dir}/{filename}'\n",
        "      logger.debug(f'Processing file {file_path}')\n",
        "      # parse file\n",
        "      xmldoc = etree.parse(file_path)\n",
        "      # check if it's a text resource record\n",
        "      md_profile_values = xmldoc.xpath('/cmd:CMD/cmd:Header/cmd:MdProfile/text()', namespaces=CMD_NAMESPACES)\n",
        "      if not (TEXT_RESOURCE_PROFILE_ID in md_profile_values):\n",
        "        logger.debug(f'Skipping file {filename} (not a text resource record)')\n",
        "      else:\n",
        "        # get resource refs\n",
        "        resource_refs = [ref for ref\n",
        "                        in xmldoc.xpath('/cmd:CMD/cmd:Resources/cmd:ResourceProxyList/cmd:ResourceProxy/cmd:ResourceRef/text()', namespaces=CMD_NAMESPACES)\n",
        "                        if ref.startswith(FULLTEXT_RESOURCES_BASE_URL)]\n",
        "        \n",
        "        # put in index according to definition\n",
        "        for index_key in index_def:\n",
        "          values = xmldoc.xpath(index_def[index_key], namespaces=CMD_NAMESPACES)\n",
        "          \n",
        "          if values and len(values) > 0:\n",
        "            # create and/or get index for current key\n",
        "            if not index.get(index_key, None):\n",
        "              # key has not been indexed\n",
        "              index[index_key] = {}\n",
        "            key_index = index[index_key]\n",
        "\n",
        "            # add refs to key/value index\n",
        "            for value in values:\n",
        "              if not key_index.get(value, None):\n",
        "                key_index[value] = []\n",
        "              key_index[value] += resource_refs\n",
        "  return index\n",
        "\n",
        "def get_json_from_http(url, session=None):\n",
        "    logger.debug(f\"Making request: {url}\")\n",
        "    if session is None:\n",
        "        response = requests.get(url).text\n",
        "    else:\n",
        "        response = session.get(url).text\n",
        "    logger.debug(f\"API response: {url}\")\n",
        "    try:\n",
        "        return json.loads(response)\n",
        "    except json.JSONDecodeError:\n",
        "        logger.error(f\"Error decoding response from {url}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_fulltext(urls_set, cache, progressbar=None):\n",
        "  text = []\n",
        "  for url in urls_set:\n",
        "    from_cache = cache.get(url, None)\n",
        "    if from_cache:\n",
        "      # use from cache\n",
        "      text_value = from_cache\n",
        "    else:\n",
        "      # retrieve\n",
        "      logger.debug(f'Retrieving text from {url}')\n",
        "      json_response = get_json_from_http(url)\n",
        "      if json_response:\n",
        "        text_value = json_response.get('value', None)\n",
        "        if text_value:\n",
        "          cache[url] = text_value\n",
        "\n",
        "    if text_value:\n",
        "      text += [text_value]\n",
        "      if progressbar:\n",
        "        progressbar.value += 1\n",
        "    else:\n",
        "      logger.warning(f'No response and/or text value at {url}')\n",
        "  return text"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uEDlPNjTR1M5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Constants and settings\n",
        "COLLECTIONS = {'Finland': '9200301', 'Latvia': '9200303', 'Luxembourg': '9200396'}\n",
        "COLLECTION_NAME = \"Latvia\" #@param [\"Finland\", \"Latvia\", \"Luxembourg\"]\n",
        "COLLECTION = COLLECTIONS[COLLECTION_NAME]\n",
        "\n",
        "INDEX_DEF = {\n",
        "    'language': '/cmd:CMD/cmd:Components/cmdp:TextResource/cmdp:Language/cmdp:code/text()',\n",
        "    'years': '/cmd:CMD/cmd:Components/cmdp:TextResource/cmdp:TemporalCoverage/cmdp:Start/cmdp:year/text()'\n",
        "}\n",
        "\n",
        "CMDI_TARBALL_URL='https://alpha-vlo.clarin.eu/data/test/europeana-aggregations.tar.gz'\n",
        "\n",
        "CMDIS_DIR='./cmdis'\n",
        "OUTPUT_DIR='./output'"
      ],
      "metadata": {
        "id": "aAJBsxBFQq3y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval and indexing of the CMDI metadata for the newspaper collections"
      ],
      "metadata": {
        "id": "nD6JXHZBY0BA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to download an archive (`.tar.gz` file) from the CLARIN server"
      ],
      "metadata": {
        "id": "s6uSm-GTZi7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_Wcdg2mTnnIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71fcc9ed-a983-4377-97e1-b6a175d4a634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Retrieving CMDIs\n"
          ]
        }
      ],
      "source": [
        "logger.info('Retrieving CMDIs')\n",
        "tarball_filename = retrieve_cmdis_archive(CMDI_TARBALL_URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we unpack the collection that we are interested in from the downloaded archive, so that we can access the individual metadata records"
      ],
      "metadata": {
        "id": "xRMOY0SQZZsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(f'Reading tarball contents (looking for {COLLECTION})')\n",
        "\n",
        "if not unpack_collection(tarball_filename, CMDIS_DIR, COLLECTION):\n",
        "  raise RuntimeError(f'Failed to extract member {collection} from tarball!')\n",
        "\n",
        "COLLECTION_FILES_DIR=f'{CMDIS_DIR}/{COLLECTION}'\n",
        "logger.info(f'CMDI files available in {COLLECTION_FILES_DIR}/')"
      ],
      "metadata": {
        "id": "4rTuvO3kIYg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59eeab2-d738-4b2b-86bf-76b1b78ef801"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Reading tarball contents (looking for 9200303)\n",
            "INFO:__main__:Extracting 9200303 from cmdis.tgz to ./cmdis/\n",
            "INFO:__main__:CMDI files available in ./cmdis/9200303/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metadata records are now available to be processed.\n",
        "\n",
        "In the next cell, the links to the full text resources are **indexed** based on the index definition in the configuration section."
      ],
      "metadata": {
        "id": "GMxzoPcPZMzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Indexing resource links from records')\n",
        "index = index_filenames(INDEX_DEF, COLLECTION_FILES_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I3BiqAgXBha",
        "outputId": "c3b736c3-79ed-40d9-a7f9-59ba7fb6e90e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Indexing resource links from records\n",
            "INFO:__main__:Skipping file index.json (not an XML file)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info('Index summary:')\n",
        "for index_key in index:\n",
        "  key_index = index[index_key]\n",
        "  logger.info(f'{index_key}: {sorted(list(key_index))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKzeYkq3ODlH",
        "outputId": "981f988e-f622-497f-c147-c95da5d80dd9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Index summary:\n",
            "INFO:__main__:language: ['deu', 'est', 'lav', 'pol', 'rus']\n",
            "INFO:__main__:years: ['1868', '1869', '1870', '1871', '1872', '1873', '1874', '1875', '1876', '1877', '1878', '1879', '1880', '1881', '1882', '1883', '1884', '1885', '1886', '1887', '1888', '1889', '1890', '1891', '1892', '1893', '1894', '1895', '1896', '1897', '1898', '1899', '1900', '1901', '1902', '1903', '1904', '1905', '1906', '1907', '1908', '1909', '1910', '1911', '1912', '1913', '1914', '1915', '1916', '1917', '1918', '1919', '1920', '1921', '1922', '1923', '1924', '1925', '1926', '1927', '1928', '1929', '1930', '1931', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939', '1940', '1941', '1942', '1943', '1944', '1945', '1946']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare for processing"
      ],
      "metadata": {
        "id": "ZO2tmTSCZ63l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we segment the data based on properties from the metadata. In this case, we use language and year of publication."
      ],
      "metadata": {
        "id": "DilOg5ezZ-Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create segments, then retrieve text\n",
        "\n",
        "urls_lav = set(index['language']['lav'])\n",
        "urls_deu = set(index['language']['deu'])\n",
        "urls_20s = set(flatten_list([ index['years'][year] for year in list(index['years']) if (int(year) >= 1920) and (int(year) < 1930) ]))\n",
        "urls_30s = set(flatten_list([ index['years'][year] for year in list(index['years']) if (int(year) >= 1930) and (int(year) < 1940) ]))\n",
        "\n",
        "# make intersections\n",
        "segments_urls = {\n",
        "  # 'lav_20s': urls_lav.intersection(urls_20s),\n",
        "  # 'lav_30s': urls_lav.intersection(urls_30s),\n",
        "  'deu_20s': urls_deu.intersection(urls_20s),\n",
        "  'deu_30s': urls_deu.intersection(urls_30s),\n",
        "}"
      ],
      "metadata": {
        "id": "I770cIOfJlOQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we only have resource URLs. In the next cell, the actual full text content is downloaded (and/or retrieved from cache) for the URLs in the segments that we have defined. \n",
        "\n",
        "Note that this can take a while!"
      ],
      "metadata": {
        "id": "PfzouzPCaJ61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = sum([len(segments_urls[seg_name]) for seg_name in segments_urls])\n",
        "progress_bar = widgets.IntProgress(\n",
        "  min = 0, max = total,\n",
        "  description = 'Retrieving:', bar_style = 'info',\n",
        ")\n",
        "display(progress_bar)\n",
        "\n",
        "# retrieve text for segments\n",
        "segments_text = {}\n",
        "count = 0\n",
        "with shelve.open('fulltext_cache') as cache:\n",
        "  for seg_name in segments_urls:\n",
        "    urls = segments_urls[seg_name]\n",
        "    logger.info(f\"Retrieving text content for segment '{seg_name}' ({len(urls)} urls)\")\n",
        "    segments_text[seg_name] = get_fulltext(urls, cache, progress_bar)\n",
        "\n",
        "progress_bar.bar_style = 'success'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "dbb4214712ba498ca613df201a9ee1b7",
            "bc0fa470bd2c46d1a9d416396fa150e7",
            "d6a9d7ace1434bb6844aa089a6acd3e2"
          ]
        },
        "id": "BrXwQcC0e2pV",
        "outputId": "1e582e98-de73-43b4-c749-ef2b6da39091"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbb4214712ba498ca613df201a9ee1b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntProgress(value=0, bar_style='info', description='Retrieving:', max=3362)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Retrieving text content for segment 'deu_20s' (3079 urls)\n",
            "INFO:__main__:Retrieving text content for segment 'deu_30s' (283 urls)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now save the retrieved text content to disk for later use"
      ],
      "metadata": {
        "id": "c9Grsf6Saaa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save retrieved text to file\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "for seg_name in segments_text:\n",
        "  filename=f'{OUTPUT_DIR}/{seg_name}.txt'\n",
        "  with open(filename, 'w') as out_file:\n",
        "    logger.info(f\"Writing all text for segment '{seg_name}' to '{filename}'\")\n",
        "    written = sum([out_file.write(text) for text in segments_text[seg_name]])\n",
        "    logger.info(f'{written} characters written')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlOP7V3Oe6om",
        "outputId": "72047dd0-4d1d-482b-bb80-acb8c6084ede"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Writing all text for segment 'deu_20s' to './output/deu_20s.txt'\n",
            "INFO:__main__:41932571 characters written\n",
            "INFO:__main__:Writing all text for segment 'deu_30s' to './output/deu_30s.txt'\n",
            "INFO:__main__:1648545 characters written\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing"
      ],
      "metadata": {
        "id": "2BhysRFdaiVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We run the Tensorflow tokenizer on each of the data segments"
      ],
      "metadata": {
        "id": "1Qw8b771akgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "segments_tokenized = {}\n",
        "for seg_name in segments_text:\n",
        "  logger.info(f\"Running tokenizer on text for '{seg_name}'\")\n",
        "  tokenizer = Tokenizer(1000)\n",
        "  tokenizer.fit_on_texts(segments_text[seg_name])\n",
        "  segments_tokenized[seg_name] = tokenizer.word_index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4-IbXyKhSse",
        "outputId": "6c385c59-1131-4131-d6ea-591274a79429"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Running tokenizer on text for 'deu_20s'\n",
            "INFO:__main__:Running tokenizer on text for 'deu_30s'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the token collections to disk for later use"
      ],
      "metadata": {
        "id": "fxF7uYE1aooT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save tokenizer output to file\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "for seg_name in segments_tokenized:\n",
        "  filename=f'{OUTPUT_DIR}/{seg_name}_tokenized.json'\n",
        "  with open(filename, 'w') as out_file:\n",
        "    logger.info(f\"Writing all text for segment '{seg_name}' to '{filename}'\")\n",
        "    logger.info(f\"Preview: {list(segments_tokenized[seg_name])[:10]}...\")\n",
        "    json.dump(segments_tokenized[seg_name], out_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tVlL99UmEuq",
        "outputId": "6cc64acb-7bac-4373-ca2b-41139f4acdc3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Writing all text for segment 'deu_20s' to './output/deu_20s_tokenized.json'\n",
            "INFO:__main__:Preview: ['der', 'die', 'und', 'in', 'zu', 'von', 'den', 'mit', 'des', 'das']...\n",
            "INFO:__main__:Writing all text for segment 'deu_30s' to './output/deu_30s_tokenized.json'\n",
            "INFO:__main__:Preview: ['der', 'die', 'und', 'in', 'den', 'des', 'zu', 'das', 'von', '—']...\n"
          ]
        }
      ]
    }
  ]
}